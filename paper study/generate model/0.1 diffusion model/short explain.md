# Diffusion Models in Vision: A Survey

## 저널 : IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, [2022년 기준 Q1, 1%]

https://arxiv.org/pdf/2209.04747

## 저자 :  ![Alt text](image.png)


**논문의 주요 내용**:
- **Diffusion Models**: Diffusion 모델은 컴퓨터 비전 분야에서 최근 주목받는 주제로, 생성 모델링 분야에서 뛰어난 결과를 보여주고 있습니다. Diffusion 모델은 두 단계로 구성되어 있습니다.
  1. **Forward Diffusion Stage**: 입력 데이터에 가우시안 잡음을 여러 단계에 걸쳐 점진적으로 추가하여 데이터를 변조합니다.
  2. **Reverse Diffusion Stage**: 모델은 Diffusion 과정을 점진적으로 거꾸로 되돌리면서 원래의 입력 데이터를 복구하는 작업을 합니다.

- 이러한 모델들은 생성된 샘플의 품질과 다양성 때문에 널리 인정받고 있지만, 샘플링 중에 많은 단계가 포함되어 있기 때문에 계산 부하가 크다는 단점이 있습니다.

- 이 논문에서는 시각 분야에서의 denoising diffusion 모델에 관한 기사를 포괄적으로 검토하며, 이론적 및 실용적 기여를 포함합니다.

- 또한, diffusion 모델과 다른 딥 생성 모델, 예를 들면, variational auto-encoders, generative adversarial networks, energy-based models, autoregressive models 및 normalizing flows와의 관계에 대해서도 논의합니다.

- 마지막으로, diffusion 모델의 현재의 한계와 미래 연구 방향에 대한 흥미로운 아이디어를 제시합니다.

![Alt text](image-2.png)

**Fig. 2**: 이 그림은 Stable Diffusion 모델을 사용하여 생성된 이미지를 보여줍니다. 이 모델은 다양한 텍스트 프롬프트를 기반으로 이미지를 생성합니다. 예를 들어, "Mars에서 물을 발견하는 로버"나 "컴퓨터에서 이메일을 읽는 토끼"와 같은 텍스트 프롬프트를 기반으로 한 이미지가 생성됩니다. 이러한 이미지는 [https://beta.dreamstudio.ai/dream](https://beta.dreamstudio.ai/dream) 플랫폼을 통해 생성되었습니다.

**Diffusion Models의 세부 카테고리**:
1. **Denoising Diffusion Probabilistic Models (DDPMs)**: 이 모델은 비균형 열역학 이론에서 영감을 받았습니다. DDPMs는 잠재 변수를 사용하여 확률 분포를 추정하는 잠재 변수 모델입니다. 이 관점에서 DDPMs는 VAEs의 특별한 종류로 볼 수 있습니다.
2. **Noise Conditioned Score Networks (NCSNs)**: 이 모델은 다양한 잡음 수준에서 변조된 데이터 분포의 점수 함수를 추정하기 위해 점수 매칭을 통해 공유된 신경망을 훈련시키는 데 기반을 둡니다.
3. **Stochastic Differential Equations (SDEs)**: SDEs는 Diffusion을 모델링하는 다른 방법으로, Diffusion 모델의 세 번째 하위 카테고리를 형성합니다. 이 방식은 효율적인 생성 전략과 강력한 이론적 결과를 제공합니다.

- 이 논문은 Diffusion 모델링 프레임워크를 세 가지 일반적인 카테고리로 분류하고, 다른 딥 생성 모델과의 관계를 논의합니다. 
  - 또한, 컴퓨터 비전에서 적용된 Diffusion 모델의 다양한 관점에서의 분류를 소개하고, 현재의 Diffusion 모델의 한계와 미래 연구 방향을 제시합니다.

**주요 기여**:
1. 최근 시각 분야에서 Diffusion 모델을 기반으로 한 많은 연구가 나타났기 때문에, 이 논문은 컴퓨터 비전에서의 denoising diffusion 모델에 대한 포괄적인 문헌 검토를 제공합니다.
2. Diffusion 모델의 다양한 관점에서의 분류를 제시하여, 특정 도메인에 적용된 Diffusion 모델에 대한 연구를 하는 다른 연구자들이 관련 연구를 빠르게 찾을 수 있도록 도움을 줍니다.

![Alt text](image-3.png)

**Fig. 3**: 이 그림은 세 가지 다른 Diffusion 모델 형식을 보여줍니다: 확률론적 미분 방정식 (SDEs), denoising diffusion 확률 모델 (DDPMs), 그리고 noise conditioned score 네트워크 (NCSNs). 각 모델은 데이터를 잡음으로 변환하는 전방향 프로세스와, 그 잡음을 데이터로 다시 변환하는 생성 프로세스로 구성됩니다. 이 그림은 이러한 프로세스를 모든 세 가지 형식에 대해 시각화합니다.

**Diffusion 모델의 핵심 개념**:
- Diffusion 모델은 훈련 데이터 구조를 점진적으로 악화시키는 프로세스를 역으로 학습하는 확률론적 생성 모델입니다. 따라서 훈련 절차는 전방향 Diffusion 프로세스와 후방향 Denoising 프로세스의 두 단계로 구성됩니다.
- 전방향 프로세스는 각 입력 이미지에 저수준의 잡음을 여러 단계에 걸쳐 추가하는 것으로 구성됩니다. 
  - 훈련 데이터는 순수한 가우시안 잡음이 될 때까지 점진적으로 파괴됩니다.
- 후방향 프로세스는 전방향 Diffusion 프로세스를 역으로 수행하는 것으로 구성됩니다. 
  - 동일한 반복적인 절차가 사용되지만, 잡음은 순차적으로 제거되므로 원래의 이미지가 다시 생성됩니다.

다음 세 섹션에서는 세 가지 Diffusion 모델 형식, 즉 denoising diffusion 확률 모델, noise conditioned score 네트워크, 그리고 첫 두 방법을 일반화하는 확률론적 미분 방정식에 대해 소개합니다. 각 형식에 대해 데이터에 잡음을 추가하는 프로세스, 이 프로세스를 역으로 학습하는 방법, 그리고 추론 시간에 새로운 샘플을 생성하는 방법을 설명합니다.

**2.1 Denoising Diffusion Probabilistic Models (DDPMs)**:
- **전방향 프로세스**: DDPMs는 훈련 데이터를 가우시안 잡음을 사용하여 점진적으로 손상시킵니다.
  -  주어진 손상되지 않은 훈련 샘플 x0에서, 잡음이 있는 버전 x1, x2, ..., xT는 다음의 Markovian 프로세스에 따라 얻어집니다.


- **역방향 프로세스**: 위에서 언급한 속성을 활용하면, 우리는 샘플 xT를 N(0;I)에서 시작하여 역방향 단계 p(xt-1|xt)를 따라 p(x0)에서 새로운 샘플을 생성할 수 있습니다. 
  - 이 단계를 근사하기 위해, 잡음 이미지 xt와 시간 단계 t의 임베딩을 입력으로 받아 평균 μ_θ(xt;t)와 공분산 σ_θ(xt;t)를 예측하는 신경망 p_θ(xt-1|xt)를 훈련시킬 수 있습니다.
- 이상적인 시나리오에서는, 모델 p_θ(x0)이 각 훈련 예제 x0에 할당하는 확률이 최대가 되도록 신경망을 최대 우도 목적으로 훈련시킬 것입니다. 
  - 그러나 p_θ(x0)는 모든 가능한 역방향 경로를 마진화하여 계산해야 하므로 계산할 수 없습니다. 이 문제의 해결책은 음의 로그 우도의 변분 하한을 최소화하는 것입니다.

**2.2 Noise Conditioned Score Networks (NCSNs)**:
- 데이터 밀도 p(x)의 점수 함수는 입력에 대한 로그 밀도의 기울기로 정의됩니다, 
  - 즉, ∇x log p(x). 이러한 기울기에 의해 주어진 방향은 Langevin dynamics 알고리즘을 사용하여 무작위 샘플 (x0)에서 밀도가 높은 영역의 샘플 (xN)로 이동하는 데 사용됩니다. 
  - Langevin dynamics는 데이터 샘플링을 위해 사용할 수 있는 반복적인 방법입니다. 
  - 물리학에서 이 방법은 입자와 다른 분자 간의 상호 작용을 허용하는 분자 시스템에서 입자의 궤적을 결정하는 데 사용됩니다.
  
- **추론 시간**: Song et al. [3]은 "annealed Langevin dynamics"라는 방법을 소개합니다. 이 방법은 흰색 잡음에서 시작하여 Eq. (7)을 고정된 반복 횟수 동안 적용합니다. 필요한 기울기(점수)는 훈련된 신경망에서 제공되며, 이 신경망은 시간 단계 T에 조건을 부여합니다. 이 과정은 다음 시간 단계들에 대해서도 계속되며, 한 단계의 출력을 다음 단계의 입력으로 전달합니다. 최종 샘플은 t=0에 대한 출력입니다.

**2.3 Stochastic Differential Equations (SDEs):**

- 이 방법은 데이터 분포 p(x0)를 점진적으로 잡음으로 변환합니다. 
  - 그러나 이 방법은 이전의 두 방법을 일반화합니다. 
  - 여기서 확산 과정은 연속적으로 간주되며, 이는 확률론적 미분 방정식 (SDE)의 해결책이 됩니다. Song et al. 
  - [4]의 생성 모델은 신경망을 사용하여 점수 함수를 추정하고, 수치적 SDE 솔버를 사용하여 p(x0)에서 샘플을 생성합니다.
  -  NCSNs의 경우와 마찬가지로 신경망은 훼손된 데이터와 시간 단계를 입력으로 받아 점수 함수의 추정치를 생성합니다.
- 전방향 확산 과정의 SDE는 다음과 같은 형태를 가집니다: @x/@t = f(x;t) + β(t) * ωt. 여기서 ωt는 가우시안 잡음, f는 x와 t의 함수로서 드리프트 계수를 계산하며, β는 시간에 따라 변하는 함수로서 확산 계수를 계산합니다.

