# Semantic Compression Embedding for Generative Zero-Shot Learning

## 학회 : Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence (IJCAI-22), A+

[자세한 설명](./SC-EGG%20(2022).md)

## 저자 : ![Alt text](image.png)

https://www.researchgate.net/profile/Shiming-Chen-7/publication/362044667_Semantic_Compression_Embedding_for_Generative_Zero-Shot_Learning/links/6356500d12cbac6a3eee75cd/Semantic-Compression-Embedding-for-Generative-Zero-Shot-Learning.pdf

## 요약
- 제로샷 학습(ZSL)에서 생성 방법은 시각-의미 도메인 간의 차이를 줄이기 위해 암시적 매핑을 학습하고, 본질적으로 보이지 않는 샘플을 합성하여 본질적으로 보이는 클래스와 보이지 않는 클래스 간의 데이터 불균형을 처리하는 데 성공적으로 적용되었습니다. 
  - 그러나 **기존의 생성 방법은 사전 훈련된 CNN 백본에서 추출된 시각적 특징을 단순히 사용**합니다. 이러한 **시각적 특징은 속성 수준의 의미 정보가 부족**합니다. 
  - 따라서 본질적으로 보이는 클래스는 구별할 수 없으며, 본질적으로 보이는 클래스에서 보이지 않는 클래스로의 지식 전송이 제한됩니다. 
- 이 문제를 해결하기 위해, **우리는 의미 압축 임베딩 네트워크(SCEN)와 임베딩 가이드 생성 네트워크(EGGN)를 연속적으로 사용하는 새로운 의미 압축 임베딩 가이드 생성(SC-EGG) 모델을 제안**합니다. 
  - **SCEN은 각 샘플에 대한 속성 수준의 로컬 특징 그룹을 추출하고 이를 새로운 저차원 시각적 특징으로 further 압축**합니다. 
  - 따라서 밀도가 높은 의미 시각 공간이 얻어집니다. 
  - E**GGN은 클래스 수준의 의미 공간에서 밀도가 높은 의미 시각 공간으로의 매핑을 학습하여 합성된 밀도가 높은 의미 보이지 않는 시각적 특징의 구별성을 향상**시킵니다. 
- 세 가지 벤치마크 데이터셋, 즉 CUB, SUN 및 AWA2에서의 광범위한 실험은 SC-EGG의 현재 최첨단 방법 및 기준선에 대한 중요한 성능 향상을 보여줍니다.

![Alt text](image-1.png)

## 1. Introduction
- 배경: 최근의 지도 학습 기반 딥러닝의 뛰어난 성능은 수동으로 레이블이 지정된 대량의 시각 샘플에 의존합니다. 
  - 그러나 이러한 방법들은 훈련 세트에 없는 클래스의 객체를 인식하는 데 실패합니다.


- 도식화: 도면 1은 동기를 설명합니다. 
  - 기존의 **생성 ZSLs는 클래스 수준의 의미 공간에서 CNN 백본 시각 공간으로의 매핑을 학습하는데, 이 시각 공간은 속성 수준의 의미 정보가 부족**합니다. 
  - **결과적으로 두 개의 본질적으로 보이는 클래스는 혼동되며, 본질적으로 보이는 클래스에서 보이지 않는 클래스로의 지식 전송도 제한**됩니다. 
  - 반면, S**C-EGG는 의미 압축 임베딩에 의해 학습된 더 구별력 있는 밀도가 높은 시각 공간에서 클래스 수준의 의미 공간으로의 매핑을 학습하여, 고품질의 보이지 않는 시각 특징을 합성**합니다.

## 3. Proposed Method
- Overview:
  - SC-EGG 모델: 그림 2에 나와 있는 것처럼 제안된 의미 압축 임베딩 가이드 생성 (SC-EGG) 모델은 의미 압축 임베딩 네트워크 (SCEN)와 임베딩 가이드 생성 네트워크 (EGGN)를 연속적으로 사용합니다.
    - SCEN: SCEN은 지역 임베딩 네트워크 (LEN)와 글로벌 임베딩 네트워크 (GEN)를 사용하여 의미 압축을 위한 지역-글로벌 일관된 임베딩을 학습합니다.
    - EGGN: EGGN은 글로벌 분류기에 의해 가이드되는 의미-시각 매핑을 학습하기 위해 생성 모델 (TF-V AEGAN)을 포함하며, 이 글로벌 분류기는 GEN의 글로벌 분류기와 매개 변수를 공유합니다.

### 3.1 Semantic Compression Embedding Network (SCEN):
- 목적: SCEN은 지역-글로벌 의미 일관성 특징 학습에 의해 밀도가 높은 의미 시각 공간을 학습합니다. 
  - 이 네트워크는 지역 임베딩 교차 엔트로피 손실, 글로벌 임베딩 교차 엔트로피 손실, 및 의미 일관성 회귀 손실에 의해 제약됩니다.

- Local Embedding Network (LEN): LEN은 속성 기반 주의 메커니즘을 사용하여 속성 수준의 의미와 관련된 이미지 영역을 식별하고, 이러한 영역을 사용하여 속성에 정렬된 지역 시각 특징의 그룹을 나타냅니다.

- Global Embedding Network (GEN): GEN은 의미 압축 모듈 SC와 글로벌 시각 특징 분류기 CLSg로 구성됩니다. 
  - SC는 속성 수준의 의미와 관련된 지역 시각 특징을 밀도가 높은 저차원 글로벌 시각 특징으로 압축합니다.



### **3.2 Embedding Guided Generative Network (EGGN)**:
- **개요**: EGGN은 **클래스 수준의 의미 벡터에서 SCEN에 의해 학습된 밀도가 높은 의미 시각 특징으로의 매핑을 학습**합니다. 
  - 이 밀도가 **높은 의미 시각 특징은 저차원이며 속성 수준의 의미와 관련**이 있습니다. 
  - 따라서 **EGGN은 구별력 있는 보이지 않는 특징을 합성**할 수 있습니다.

- **TF-V AEGAN 기반**: EGGN은 TF-V AEGAN을 기반으로 합니다. 이 네트워크는 변이형 오토인코더 (V AE)와 생성적 적대 네트워크 (GAN)를 포함합니다.
  -  V AE는 인코더와 디코더로 구성되며, GAN은 V AE의 디코더와 동일한 생성기와 판별기로 구성됩니다. 
  -  추가로, 의미 임베딩 디코더와 피드백 모듈도 포함됩니다.

- **TF-V AEGAN의 기본 손실**: TF-V AEGAN의 기본 손실은 다음과 같이 정의됩니다:
  - \( L_{VG} = L_{VAE} + \lambda_w L_{WGAN} + \lambda_r L_{Rec} \)
  여기서 \( L_{VAE} \)는 변이형 손실, \( L_{WGAN} \)은 WGAN 손실, \( L_{Rec} \)는 재구성 손실입니다.

- **Embedding Guided Synthesis Loss**: EGGN이 구별력 있는 특징을 합성하도록 하고, 합성된 보이지 않는 특징이 본질적으로 보이는 클래스에 과적합되지 않도록 하기 위해 임베딩 가이드 합성 손실이 도입되었습니다. 
  - 이 손실은 GEN의 글로벌 분류기와 매개 변수를 공유하는 분류기를 기반으로 합니다.



### **3.3 Model Optimization**:
- **훈련 단계**:
  1. **Stage 1**: SCEN을 지역 및 글로벌 임베딩 교차 엔트로피 손실로 훈련하여 속성 수준 의미 관련 지역 특징을 학습합니다.
  2. **Stage 2**: LEN의 매개 변수를 고정하고 GEN을 의미 일관성 회귀 손실로 업데이트하여 SCEN을 훈련합니다.
  3. **Stage 3**: 훈련된 SCEN을 사용하여 밀도가 높은 의미 시각 특징을 추출하고, EGGN을 훈련하여 클래스 수준 의미 공간에서 밀도가 높은 의미 시각 공간으로의 매핑을 학습합니다.

### **3.4 Classification**:
- **후처리**: 훈련 후 SCEN을 사용하여 본질적으로 보이는 샘플의 밀도가 높은 의미 시각 특징을 추출하고, EGGN의 생성기를 사용하여 보이지 않는 특징을 합성합니다. 그런 다음, 이 특징들을 사용하여 CZSL 분류기와 GZSL 분류기를 훈련합니다.
- **추론**: 테스트 특징은 SCEN으로 처리되어 밀도가 높은 의미 시각 특징을 얻고, 이 특징은 CZSL 또는 GZSL 분류기의 입력으로 사용되어 ZSL 예측을 수행합니다.

## **4. Experiments**:
- 이 섹션에서는 논문의 실험적인 부분을 다룹니다. CUB, SUN, AWA2와 같은 표준 ZSL 벤치마크 데이터셋에서 제안된 SC-EGG를 평가합니다. 실험은 CZSL 및 GZSL 작업에서 top-1 정확도를 측정하여 수행됩니다.


### **4.1 Comparison with State of the Arts**:
- **비교 기준**: SC-EGG는 귀납적 방법이므로, 다른 귀납적 방법들과의 공정한 비교를 위해 이를 다른 방법들과 비교합니다.
- **결과**: CZSL 및 GZSL 설정에서 CUB, SUN, AWA2에서 최첨단 방법들과의 비교 결과를 보여줍니다. CZSL 설정에서 SC-EGG는 SUN에서 69.2% 및 AWA2에서 78.2%의 최고 정확도를 달성하며, 다른 모든 방법들과 비교했을 때 3.2% 및 4.6%의 중요한 이득을 얻습니다. CUB에서는 SC-EGG가 여전히 75.1%의 top-1 정확도로 경쟁력 있는 성능을 보여줍니다. GZSL 설정에서 SC-EGG는 CUB에서 68.5%, SUN에서 44.3%, AWA2에서 72.4%의 조화 평균 (H)으로 최고의 성능을 달성합니다.

![Alt text](image-4.png)

### **4.2 Ablation Study**:
- **목적**: SC-EGG의 다양한 구성 요소의 효과를 평가하기 위해 수행됩니다.
- **결과**: SC-EGG의 기본 버전 (즉, TF-V AEGAN)의 결과는 SC-EGG의 전체 버전보다 훨씬 나쁘며, CUB에서 Acc=H가 6.8% 및 8.2%, SUN에서 2.0% 및 1.1% 감소합니다. SCEN의 지역 분류 제약 없이 SCEN을 포함하면 (즉, SC-EGG w/o LLCE), 모델은 CUB에서 4.1% 및 4.3%, SUN에서 1.4% 및 1.9%의 Acc=H 감소로 전체 SC-EGG에 비해 나쁜 ZSL 성능을 보여줍니다.

![Alt text](image-5.png)

![Alt text](image-2.png)

### **4.3 Qualitative Results**:
- **시각화**: 그림 3에서는 두 개의 임의로 선택된 샘플의 SCEN의 주의 지도의 시각화를 보여줍니다. 첫 번째 열은 입력 이미지를 보여주고, 두 번째 열은 GEN의 전역 주의 지도를 보여줍니다.

### **4. Experiments (계속)**

![Alt text](image-3.png)

#### **4.3 Qualitative Results (계속)**:
- **t-SNE 시각화**: 그림 4에서는 CNN 백본 시각 공간과 밀도가 높은 의미 시각 공간에서 실제 본질적/보이지 않는 및 합성 보이지 않는 시각 특징의 t-SNE 시각화를 보여줍니다. 
  - 결과는 밀도가 높은 의미 시각 공간에서의 시각 특징이 CNN 백본보다 실제 본질적, 실제 보이지 않는, 및 합성 보이지 않는 클래스에서 더 구별력 있음을 보여줍니다.

### **5. 결론**:
- 이 논문에서는 ZSL을 위한 새로운 의미 압축 임베딩 가이드 생성 모델 (SC-EGG)을 제안합니다. 
  - SC-EGG는 의미 압축 임베딩 네트워크 (SCEN)와 임베딩 가이드 생성 네트워크 (EGGN)를 연속적으로 사용합니다. 
  - SCEN은 의미 압축 임베딩을 통해 구별력 있는 밀도가 높은 의미 시각 공간을 학습하며, EGGN은 SCEN의 지침 하에 클래스 수준 의미 공간에서 밀도가 높은 의미 시각 공간으로의 암시적 매핑을 학습하여 고품질의 보이지 않는 특징을 합성합니다. 
  - 세 가지 인기 있는 벤치마크 데이터셋에서의 광범위한 실험은 SC-EGG의 ZSL에 대한 우월성을 보여줍니다.

### **감사의 말**:
이 연구는 부분적으로 NSFC, 허베이 주의 기술 혁신 특별 프로젝트, 허베이 주의 핵심 R&D 계획, 허베이 주의 자연 과학 기금, 중국 과학 기술 협회의 젊은 엘리트 과학자 후원 프로그램에 의해 지원되었습니다.

이 페이지는 "Experiments" 섹션의 마지막 부분과 "Conclusion" 섹션, 그리고 감사의 말을 포함하고 있습니다. 더 많은 세부 사항이나 다음 페이지의 내용을 원하시면 알려주세요!


# 나의 의견:
 -  이 논문의 주요 기여는 기존의 생성적 ZSL 방법이 CNN 백본에서 추출된 시각적 특징을 단순히 사용하는 것에 반해, SC-EGG 모델을 통해 속성 수준의 의미 정보를 포함하는 밀도가 높은 시각적 공간을 학습하려고 시도한다.

- 이러한 접근 방식은 ZSL의 성능을 향상시키기 위한 중요한 단계일 수 있습니다. 
  - 속성 수준의 의미 정보를 포함하는 시각적 특징을 사용하면, 본질적으로 보이는 클래스와 보이지 않는 클래스 간의 지식 전송이 향상될 수 있다.
  -  이는 ZSL의 주요 도전 과제 중 하나인 본질적으로 보이는 클래스와 보이지 않는 클래스 간의 데이터 불균형 문제를 해결하는 데 도움이 될 수 있다.
