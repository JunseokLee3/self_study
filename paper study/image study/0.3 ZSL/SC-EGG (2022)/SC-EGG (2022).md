# Semantic Compression Embedding for Generative Zero-Shot Learning

## 학회 : Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence (IJCAI-22), A+

## 저자 : ![Alt text](image.png)

https://www.researchgate.net/profile/Shiming-Chen-7/publication/362044667_Semantic_Compression_Embedding_for_Generative_Zero-Shot_Learning/links/6356500d12cbac6a3eee75cd/Semantic-Compression-Embedding-for-Generative-Zero-Shot-Learning.pdf

## Abstract :

- 생성 방법은 시각적-의미적 도메인 격차를 완화하기 위한 암시적 매핑을 학습하고 보이지 않는 샘플을 합성하여 보여진 클래스와 보이지 않는 클래스 간의 데이터 불균형을 처리함으로써 제로샷 학습(ZSL)에 성공적으로 적용되었습니다. 
  - 그러나 기존의 생성 방법은 단순히 사전 훈련된 CNN 백본에 의해 추출된 시각적 특징을 사용합니다. 
  - 이러한 시각적 특징에는 속성 수준의 의미적 정보가 부족합니다. 
  - 결과적으로 보여진 클래스는 구별할 수 없고, 보여진 클래스에서 보이지 않는 클래스로의 지식 전달은 제한됩니다. 

- 이 문제를 해결하기 위해 의미 압축 임베딩 네트워크(SCEN)와 임베딩 유도 생성 네트워크(EGN)를 계단식으로 연결하는 새로운 의미 압축 임베딩 유도 생성(SC-EGG) 모델을 제안합니다.
  - SCEN은 각 샘플에 대해 속성 수준 로컬 피쳐 그룹을 추출하고 이들을 새로운 저차원 시각적 피쳐로 추가 압축합니다.
  - 따라서 밀도 높은 의미론적 시각 공간이 얻어집니다.
  - EGN은 클래스 수준의 의미론적 공간에서 조밀한 의미론적 시각적 공간으로의 매핑을 학습하여 합성된 조밀한 의미론적 보이지 않는 시각적 특징의 판별성을 향상시킵니다. 
- CUB, SUN 및 AWA2와 같은 세 가지 벤치마크 데이터 세트에 대한 광범위한 실험은 현재의 최첨단 방법과 기준에 비해 SC-EGG의 상당한 성능 향상을 보여줍니다.

![Alt text](image-1.png)

## 1 Introduction

- 최근, ZSL의 생성 방법(즉, 생성 ZSL)은 상당한 발전을 달성했습니다 [Chen et al., 2021c]. 
  - Generative models은 일반적으로 보이는 데이터를 사용하여 클래스 수준의 의미 공간에서 시각적 공간으로의 암시적 매핑을 학습하고 보이지 않는 클래스의 의미 벡터에서 보이지 않는 시각적 특징을 합성합니다. 
  - 따라서, ZSL은 표준 감독 분류 작업으로 변환되어 보이는 클래스와 보이지 않는 클래스 사이의 데이터 불균형 문제 및 시각적-의미적 도메인 격차 문제를 해결하는 데 도움이 됩니다.

- 그러나 기존 생성 ZSL 방법은 단순히 클래스 수준 시맨틱 공간에서 CNN 백본 시각적 공간(예: 사전 훈련된 CNN 백본에서 직접 추출한 시각적 특징으로 표시됨)으로의 매핑 기능을 학습하는데, 이는 ZSL에서 보이는 클래스를 보이지 않는 클래스로 지식을 전달하는 데 중요한 속성 수준 시맨틱 정보(예: "빌 컬러 옐로우" 및 "헤드 패턴 플레인")가 부족합니다.
  -  예를 들어, 그림 1(a)에 나타낸 바와 같이, 사전 훈련된 CNN 백본은 상이한 미세 조류 범주의 세 가지 샘플에 대해 "Bird"에 대한 의미론적 정보를 포함하는 시각적 특징만을 추출할 수 있으며, 이는 충분히 차별적이지 않습니다. 
  -  이와 같이, 보이는 클래스는 혼란스럽고, 보이는 클래스에서 보이지 않는 클래스로 전달되는 지식도 제한됩니다.


- 위의 문제를 해결하기 위해 의미 압축 임베딩 네트워크(SCEN)와 임베딩 유도 생성 네트워크(EGN)를 계단식으로 연결하는 새로운 의미 압축 임베딩 유도 생성(SC-EGG) 모델을 제안합니다. SCEN은 로컬 임베딩 네트워크(LEN)와 글로벌 임베딩 네트워크(GEN)로 구성됩니다. 
  - LEN은 의미론이 속성에 해당하는 로컬 시각적 특징의 그룹을 추출합니다. 
  - 특징 합성을 위한 차원의 저주를 고려하여 GEN이 각 샘플의 로컬 시각적 특징과 의미론이 일치하는 저차원 글로벌 시각적 특징을 학습할 수 있도록 새로운 의미 일치 회귀 손실을 도입합니다. 
  - 따라서 그림 1(b)와 같이 속성 수준의 의미 표현을 글로벌 시각적 특징으로 압축하고 밀도 있는 의미론적 시각 공간을 얻습니다. EGN은 더 나은 지식 전달을 위해 클래스 수준의 의미 벡터에서 밀도 있는 시각적 공간으로의 매핑을 학습하기 위해 생성 모델을 채택합니다. 
  - 보이는 클래스에 모델을 과적합하는 것을 완화하기 위해 훈련된 분류기를 GEN에서 사용하여 EGN의 보이는 클래스와 보이지 않는 클래스 모두에 대한 시각적 특징 합성을 제한하는 임베딩 유도 합성 손실을 추가로 도입합니다. 
- 마지막으로 훈련된 EGN을 사용하여 보이지 않는 시각적 특징의 양을 합성하여 분류기를 훈련시키고, 이는 ZSL 분류에 사용됩니다.


**Our main contributions are summarized as follows:**

- CNN 백본 시각적 특징의 속성 수준 시맨틱 누락 문제를 해결하기 위해 SC-EGG(Semantic Compression Membedding Guided Generation) 모델이라는 새로운 ZSL 방법을 제안하여 생성 ZSL의 성능을 더욱 향상시킵니다.
- 우리는 시맨틱 압축을 위한 새로운 시맨틱 일관성 있는 회귀 손실과 보이는 클래스에 과적합되는 생성 모델을 완화하기 위한 임베딩 유도 합성 손실을 제안합니다.
-  CUB [Welinder et al., 2010], SUN [Patterson and Hays, 2012] 및 AWA2 [Xian et al., 2017] 등 세 가지 도전적인 벤치마크 데이터 세트에 대한 광범위한 실험은 현재 최첨단 방법 및 기준에 비해 SCEGG의 상당한 성능 향상을 보여줍니다.

## 2 Related Work








# 나의 의견:
 -  이 논문의 주요 기여는 기존의 생성적 ZSL 방법이 CNN 백본에서 추출된 시각적 특징을 단순히 사용하는 것에 반해, SC-EGG 모델을 통해 속성 수준의 의미 정보를 포함하는 밀도가 높은 시각적 공간을 학습하려고 시도한다.

- 이러한 접근 방식은 ZSL의 성능을 향상시키기 위한 중요한 단계일 수 있습니다. 
  - 속성 수준의 의미 정보를 포함하는 시각적 특징을 사용하면, 본질적으로 보이는 클래스와 보이지 않는 클래스 간의 지식 전송이 향상될 수 있다.
  -  이는 ZSL의 주요 도전 과제 중 하나인 본질적으로 보이는 클래스와 보이지 않는 클래스 간의 데이터 불균형 문제를 해결하는 데 도움이 될 수 있다.
