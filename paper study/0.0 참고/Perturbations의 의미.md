"Perturbations" usually refer to small changes or disturbances in the system. In the context of machine learning and specifically deep learning, a perturbation could be a small change or adjustment to the parameters or weights of a model. The idea is that you start with an initial model (in this case, an identity mapping), and then you add small "perturbations" or changes to it in order to get a model that better fits your data. This concept is often used in methods such as adversarial training or in the context of studying the robustness of neural networks.